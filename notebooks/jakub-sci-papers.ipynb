{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceType": "datasetVersion",
          "sourceId": 3756201,
          "datasetId": 551982,
          "databundleVersionId": 3810704
        },
        {
          "sourceType": "modelInstanceVersion",
          "sourceId": 282751,
          "databundleVersionId": 11375937,
          "modelInstanceId": 239470
        }
      ],
      "dockerImageVersionId": 30918,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5db5c863adda488aaf948503c41b4e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c99d959ee82d4a51ac1cdb7553067324",
              "IPY_MODEL_ad886c9c1111444c9101d8d5903b056e",
              "IPY_MODEL_713f885c5a23448db57ed389256b5038"
            ],
            "layout": "IPY_MODEL_f211a749f62142b8b03e10d9e4dca3b7"
          }
        },
        "c99d959ee82d4a51ac1cdb7553067324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71355d7648224254866924478734cad0",
            "placeholder": "​",
            "style": "IPY_MODEL_95f5c48793074293b27f9f9c1b625d1b",
            "value": "Loading checkpoint shards:  50%"
          }
        },
        "ad886c9c1111444c9101d8d5903b056e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaa4a1f27dd748899ae6fd4c57ad3956",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5edc674fd4347db9d39cfd50a58cdb9",
            "value": 1
          }
        },
        "713f885c5a23448db57ed389256b5038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71b5c2e9d6a041ef8ee8082885fa550d",
            "placeholder": "​",
            "style": "IPY_MODEL_3ae07928e2644ac9b8afe3ff2f34dd4f",
            "value": " 1/2 [00:27&lt;00:27, 27.20s/it]"
          }
        },
        "f211a749f62142b8b03e10d9e4dca3b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71355d7648224254866924478734cad0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95f5c48793074293b27f9f9c1b625d1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aaa4a1f27dd748899ae6fd4c57ad3956": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5edc674fd4347db9d39cfd50a58cdb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71b5c2e9d6a041ef8ee8082885fa550d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ae07928e2644ac9b8afe3ff2f34dd4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data exploration"
      ],
      "metadata": {
        "id": "9JMHunhJqUGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import json\n",
        "from pprint import pprint\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "# import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-18T08:34:04.667626Z",
          "iopub.execute_input": "2025-03-18T08:34:04.667910Z",
          "iopub.status.idle": "2025-03-18T08:34:05.941084Z",
          "shell.execute_reply.started": "2025-03-18T08:34:04.667884Z",
          "shell.execute_reply": "2025-03-18T08:34:05.939919Z"
        },
        "id": "m12Bqhp0qUGK"
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get files from the dataset"
      ],
      "metadata": {
        "id": "qzhRcfvnqUGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"allen-institute-for-ai/CORD-19-research-challenge\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-18T08:34:08.348354Z",
          "iopub.execute_input": "2025-03-18T08:34:08.348823Z",
          "iopub.status.idle": "2025-03-18T08:34:08.897165Z",
          "shell.execute_reply.started": "2025-03-18T08:34:08.348782Z",
          "shell.execute_reply": "2025-03-18T08:34:08.895816Z"
        },
        "id": "do6PprA9qUGL",
        "outputId": "fca5e769-3c88-44ed-a7f7-690f749a104b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Path to dataset files: /kaggle/input/CORD-19-research-challenge\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "file_dir = '/kaggle/input/CORD-19-research-challenge/document_parses/pdf_json/'\n",
        "import os\n",
        "filenames = os.listdir(file_dir)\n",
        "print(\"Number of articles retrieved from biorxiv:\", len(filenames))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-18T08:34:16.123094Z",
          "iopub.execute_input": "2025-03-18T08:34:16.123466Z",
          "iopub.status.idle": "2025-03-18T08:34:55.275709Z",
          "shell.execute_reply.started": "2025-03-18T08:34:16.123436Z",
          "shell.execute_reply": "2025-03-18T08:34:55.274696Z"
        },
        "id": "-_LDekOkqUGM",
        "outputId": "34d56e53-2d47-4165-a718-217edee564c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Number of articles retrieved from biorxiv: 401214\nCPU times: user 127 ms, sys: 352 ms, total: 480 ms\nWall time: 39.1 s\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# select randomly 1000 article\n",
        "sample_file = np.random.choice(filenames, size=1000, replace=False,)\n",
        "len(sample_file)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-18T08:34:58.350898Z",
          "iopub.execute_input": "2025-03-18T08:34:58.351237Z",
          "iopub.status.idle": "2025-03-18T08:34:58.529190Z",
          "shell.execute_reply.started": "2025-03-18T08:34:58.351210Z",
          "shell.execute_reply": "2025-03-18T08:34:58.528317Z"
        },
        "id": "aE6dps41qUGM",
        "outputId": "da2c216d-1642-4f68-bc88-4c02956247cf"
      },
      "outputs": [
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "1000"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "all_files = []\n",
        "\n",
        "for filename in sample_file:\n",
        "    filename = file_dir + filename\n",
        "    file = open(filename, 'rb')\n",
        "    # TODO here would be nice to store the file locally in 'kaggle/working/'\n",
        "    all_files.append(json.load(file))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-18T08:35:09.905623Z",
          "iopub.execute_input": "2025-03-18T08:35:09.905992Z",
          "iopub.status.idle": "2025-03-18T08:35:22.003457Z",
          "shell.execute_reply.started": "2025-03-18T08:35:09.905964Z",
          "shell.execute_reply": "2025-03-18T08:35:22.002405Z"
        },
        "id": "Ah0B0TTZqUGN",
        "outputId": "7900637a-262d-49f7-e57d-19a0e5abe05e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "CPU times: user 1.79 s, sys: 471 ms, total: 2.26 s\nWall time: 12.1 s\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "BypegUFZqUGN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get previously locally stored sample"
      ],
      "metadata": {
        "id": "DqToQB98qUGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO load sample from 'kaggle/working'"
      ],
      "metadata": {
        "trusted": true,
        "id": "2XxjGqCCqUGN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract info"
      ],
      "metadata": {
        "id": "m_LPpgsRqUGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file1 = all_files[45]\n",
        "print(\"Dictionary keys:\", all_files[0].keys())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-17T15:59:29.008917Z",
          "iopub.execute_input": "2025-03-17T15:59:29.009300Z",
          "iopub.status.idle": "2025-03-17T15:59:29.014806Z",
          "shell.execute_reply.started": "2025-03-17T15:59:29.009268Z",
          "shell.execute_reply": "2025-03-17T15:59:29.013701Z"
        },
        "id": "Vc22b_o1qUGO",
        "outputId": "e9d3881b-7c75-469f-f881-81242bfea90d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Dictionary keys: dict_keys(['paper_id', 'metadata', 'abstract', 'body_text', 'bib_entries', 'ref_entries', 'back_matter'])\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [(di['section'], di['text']) for di in file1['body_text']]\n",
        "texts_di = {di['section']: \"\" for di in file1['body_text']}\n",
        "for section, text in texts:\n",
        "    texts_di[section] += text\n",
        "\n",
        "#pprint(list(texts_di.keys()))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-17T15:53:22.975471Z",
          "iopub.execute_input": "2025-03-17T15:53:22.975910Z",
          "iopub.status.idle": "2025-03-17T15:53:22.981148Z",
          "shell.execute_reply.started": "2025-03-17T15:53:22.975874Z",
          "shell.execute_reply": "2025-03-17T15:53:22.980116Z"
        },
        "id": "t_PmhcseqUGO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(file1['abstract'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-17T15:44:08.631612Z",
          "iopub.execute_input": "2025-03-17T15:44:08.632014Z",
          "iopub.status.idle": "2025-03-17T15:44:08.643933Z",
          "shell.execute_reply.started": "2025-03-17T15:44:08.631982Z",
          "shell.execute_reply": "2025-03-17T15:44:08.640993Z"
        },
        "id": "1maTqiJTqUGO",
        "outputId": "82b3fe02-709c-4fa8-914e-7ceda0830fa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[{'cite_spans': [],\n  'ref_spans': [],\n  'section': 'Abstract',\n  'text': 'The COVID -19 pandemic posed serious challenge for securing public '\n          'health worldwide. Public health preparedness and restrictions put '\n          'in place impacted many aspects of human life, including '\n          'recreational activities and access to outdoor recreational '\n          'destinations. Green spaces have become one of the few sources of '\n          'resilience during the coronavirus crisis due to their restorative '\n          'effects on psychophysical health and community well-being. The aim '\n          'of this study is to analyse the impact of the COVID -19 pandemic on '\n          'forest visitation. The results are based upon long-term visitor '\n          'data acquired via pyroelectric sensors (Eco-Counter) in three '\n          'forest districts located in Poland (Browsk, Gdansk & Kozienice '\n          'Forest Districts). The analysis covers the period between '\n          '01.01.2019 and 31.12.2020 and the results confirm changes in '\n          'recreational use in the studied forest areas during the pandemic '\n          'compared to the preceding year. However, observed changes in forest '\n          'visitation vary by pandemic period and study area. The ban on '\n          'access to forest areas significantly reduced the number of forest '\n          'visits in all studied areas. The number of visits to sub-urban '\n          'forests (Gdansk Forest District) and to remote nature-based tourist '\n          'destinations (Browsk Forest District) increased in the later '\n          'pandemic periods, especially in the summer months of 2020, while it '\n          'remained the same in a popular nearby recreation area: Kozienice '\n          'Forest District. There were only minor temporal shifts in the '\n          'distribution of weekly and daily visits. The results are important '\n          'for public health preparedness planning in crisis situations and '\n          'for provisioning conditions supporting societal health and '\n          'wellbeing. Objective data on forest visits are necessary for '\n          'successful management of forest areas and surrounding amenities. '\n          'More cross-sector collaboration and public participation would be '\n          'desirable to create sustainable, resilient, and liveable spaces for '\n          'the society.'}]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def process_article(file):\n",
        "    body = \"\"\n",
        "\n",
        "    body += file['metadata']['title']\n",
        "    body += \"\\n\\n\"\n",
        "    if len(file['abstract']) > 0:\n",
        "        body += file['abstract'][0]['section']\n",
        "        body += \"\\n\\n\"\n",
        "        body += file['abstract'][0]['text']\n",
        "        body += \"\\n\\n\"\n",
        "\n",
        "    texts = [(di['section'], di['text']) for di in file['body_text']]\n",
        "    texts_di = {di['section']: \"\" for di in file['body_text']}\n",
        "    for section, text in texts:\n",
        "        texts_di[section] += text\n",
        "\n",
        "    for section, text in texts_di.items():\n",
        "        body += section\n",
        "        body += \"\\n\\n\"\n",
        "        body += text\n",
        "        body += \"\\n\\n\"\n",
        "\n",
        "    return body\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-18T08:35:33.434000Z",
          "iopub.execute_input": "2025-03-18T08:35:33.434410Z",
          "iopub.status.idle": "2025-03-18T08:35:33.440994Z",
          "shell.execute_reply.started": "2025-03-18T08:35:33.434381Z",
          "shell.execute_reply": "2025-03-18T08:35:33.439675Z"
        },
        "id": "GuFm9peNqUGP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "docs = []\n",
        "for f in all_files:\n",
        "    try:\n",
        "        docs.append(process_article(f))\n",
        "    except:\n",
        "        pprint(f)\n",
        "        exit()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-18T08:35:38.111589Z",
          "iopub.execute_input": "2025-03-18T08:35:38.111953Z",
          "iopub.status.idle": "2025-03-18T08:35:38.217579Z",
          "shell.execute_reply.started": "2025-03-18T08:35:38.111923Z",
          "shell.execute_reply": "2025-03-18T08:35:38.216740Z"
        },
        "id": "iNsMBWCKqUGP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)\n",
        "print(docs[3])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-18T08:35:43.528699Z",
          "iopub.execute_input": "2025-03-18T08:35:43.529078Z",
          "iopub.status.idle": "2025-03-18T08:35:43.534645Z",
          "shell.execute_reply.started": "2025-03-18T08:35:43.529048Z",
          "shell.execute_reply": "2025-03-18T08:35:43.533376Z"
        },
        "id": "ixyT7OkrqUGP",
        "outputId": "dcf01334-f71d-40ed-9289-794ff4123d06"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Leadership lessons from administrators, faculty, and students during the COVID-19 pandemic\n\nAbstract\n\nIntroduction: Due to the largescale scope of the COVID-19 pandemic, strain on the higher education system in the United States has been extraordinary. Yet, with any crisis, there is the opportunity to learn, grow, and develop new knowledge and strategies to benefit educational programs moving forward. The purpose of this study is to describe the leadership lessons learned by academic pharmacy during the COVID-19 pandemic from the perspective of administrators, faculty, and students.\n\nIntroduction\n\nThe COVID-19 pandemic has been one of the largest health crises in modern history. The pandemic, caused by a novel coronavirus named SARS-CoV-2, was first identified in Wuhan, China in December 2019. 1 The virus is spread through respiratory droplets that land in the nose or mouth of nearby people, which are then inhaled into the lungs. 2 The spread of the virus among people in close contact can be quite rapid, and the pandemic led to unprecedented closings of public spaces and restrictions on travel in an attempt to limit community spread. 2 By late January 2020, China placed Wuhan under lockdown as the number of cases rose and deaths were reported. 3 Meanwhile, cases were spreading to other countries, including the United States (US). 4, 5 By the end of February 2020, COVID-19 cases began to spike in Italy, and there were reports of increasing deaths and hospitals being overrun. 6 As a response, Italy implemented a country-wide lockdown to control the number of cases. By mid-March, the US declared a national emergency due to the outbreak, and by 16 March 2020, the US government announced the \"15 Days to Slow the Spread\" effort as a way to implement social distancing at all levels of society. 7 On that same day, the governor of Tennessee recommended closing all of the state's schools in a matter of days. 8 By the end of March, most states issued stay-at-home orders. The restrictions closed many businesses and limited the number of people allowed to interact. Some of the restrictions included canceling elective surgeries in hospitals and closing restaurants, salons, places of business, and education facilities. 9, 10 Many institutions switched to or increased remote work, putting strains on occupational productivity as households became workplaces, gyms, schools, and more. 11 Due to the radical and rapid development of this pandemic, the strain on the academic system in the US has been extraordinary. Universities and schools for children of all ages were forced to pivot quickly to online learning that extended through the end of the spring 2020 semester. The gravity and speed of events that occurred from the beginning of the pandemic to the shutdowns across the US has led to a need for innovative leadership in the face of widespread crisis, especially in higher education. Although there are many reports which speak about how campus leaders should react in crises such as shootings, tornadoes, hurricanes, and other such disasters, a country-wide event of this scale is uncharted territory. [12] [13] [14] Through previous disasters affecting the education system in the US, administrators have learned the importance of agility, flexibility, appropriate communication, and strategic planning. [12] [13] [14] In a study concerning the 1999 Texas A&M Bonfire collapse, administrators at A&M noted that even though they were experiencing an unprecedented crisis, they fostered a new sense of teamwork as a result. 12 Similarly, in an article published in The Chronicle of Higher Education, the president emeritus of Tulane University compared the current COVID-19 crisis to the aftermath of Hurricane Katrina for Tulane. 15 He and other educators have emphasized the importance of ensuring the welfare of the community, focusing on what the organization can control, providing effective communication, creating a sense of community, and getting feedback from students in order to maintain continuity during an everchanging situation. [15] [16] [17] These leadership lessons hold true in the current COVID-19 pandemic, but there are still unknown effects of this crisis especially in higher education and in academic pharmacy, in particular. To address this gap in the literature, this study investigates the perceptions and effects of these challenges in a college of pharmacy (COP), with emphasis on the doctor of pharmacy program. The purpose of this study is thus to describe the leadership lessons learned by academic pharmacy during the COVID-19 pandemic from the perspective of administrators, faculty, and students.\n\nMethods\n\nA retrospective analysis was performed of qualitative data provided by three separate focus groups in spring 2020 at the University of Tennessee Health Science Center (UTHSC) College of Pharmacy. The focus groups were originally conducted as part of the college's quality improvement efforts during the COVID-19 pandemic and resulting transition to an entirely remote learning environment. Focus groups were conducted by a study investigator. The study was approved by the UTHSC Institutional Review Board. As this was a retrospective analysis, informed consent was not required.Purposive sampling was utilized to select focus group members. Each focus group was composed of one of three distinct college constituencies with unique leadership perspectives: (1) seven of nine members of the college's executive team (associate deans and department chairs; two members of the executive team were not available for the focus group); (2) five faculty members who currently or in the recent past served in college leadership positions (directors, committee chairs, etc.); and (3) all nine second-year students in an elective pharmacy leadership course, several of whom also serve in student leadership roles. Each focus group was one hour in length and conducted via Zoom (Zoom Video Communications, Inc.). Focus groups were semi-structured, and discussion was primarily guided by the following open-ended questions: (1) What leadership lessons have you learned from the COVID-19 pandemic? and (2) What leadership lessons learned during the COVID-19 pandemic will you carry forward after the crisis has passed?The Zoom sessions for each focus group were recorded to allow for review and transcription. Transcription was performed by a study investigator who was also involved in content analysis. Individually identifiable information was not included in transcripts; instead, individual participants were identified by a code number.\n\nData analysis\n\nA modified form of inductive content analysis and abstraction was used to assess qualitative data collected during the focus groups. 18, 19 To reduce reviewer bias, qualitative responses to open-ended questions were independently reviewed by the three investigators to develop a coding scheme for categories of main themes across the three focus groups, as well as subcategories (as appropriate) for each focus group population. To be considered a main theme, at least two members of each focus group must have made comment on an issue. No alternative explanations for the data were considered as the statements gathered from the focus group participants were clear, and themes and explanations derived from the recorded meetings aligned well with the focus group discussions. Table 1 identifies five main themes that emerged across all three focus groups (executive team/administrators, faculty, and students), and includes supporting quotes from different members within each group. Selected quotes reflect comments made by multiple group members. The five main themes were: open and ongoing communication, staying connected, turning crisis into opportunity, being The ability to feel \"connected\" to your team is vital. This was always true, but when you don't have face-to-face interactions it makes you realize how important that was. You must find virtual ways to stay connected.\n\nResults\n\nIt is a priority to meet the needs of people first, then the needs of the organization. Caring for others will result in a stronger organization when the crisis passes.The most important factor in survival is neither intelligence nor strength, but adaptability. This is a quote from Charles Darwin, and it has REALLY hit home with me. There is so much uncertainty and, as a planner, this has really resonated with me and I have found that if I let go of my need for order and control. Things work out in the end. We can't control the wind, but we can adjust our sails. \n\nStudents\n\nWe need to be able to say, \"I don't know\" instead of overpromising.Adapting to change and consistency in communication are essential. Also consider overcommunication and try to avoid that.Everybody is in the same boat. We need to give everyone grace and allow the team to figure out how to be flexible. Not everyone reacts to a crisis the same way.In Using student leaders to help communicate student feedback for new systems has also been helpful for faculty.We had a conversation every Monday that involved stress related to COVID. We also had a test that told staff and students whether they were in the fear zone, the knowledge zone, or the growth zone related to COVID. This weekly check-in was helpful for those working in the lab.We needed to be able to pivot and react quickly because this is a completely new situation for everyone.Projects that had already incorporated the virtual style of communication were more successful in the transition because they already had the virtual infrastructure in place. In other parts of leadership and administration, the structure disintegrated and that made it very difficult to stay focused. Having virtual \"to do\" lists or ways to keep a team accountable for tasks is essential. This helps to provide new structure especially when there is a lack of formal structure.We tried to anticipate early what could happen to lab work, how we can safeguard lab work, and how we can be busy if we are not in the lab. This situation is especially difficult for students who cannot go into the lab. Our strategy was to do as much work as possible before the labs closed so that we could work on writing during the closure. This was successful and we ended up being productive even while not being in the lab.The students lost the structure of driving to campus, sitting in their usual seats, getting their normal breaks etc. This \"pulled out the rug\" from the students and disrupted their normal routine and habits. As we progressed in the semester, we learned that the students do need as much synchronous courseThere are ways to encourage engagement even in the online setting. An example is the Zoom reaction feature and breakout rooms for discussion. Sometimes this can even encourage more engagement than the in-person setting. If we use Zoom to its full extent, it can sometimes even work better than the normal in-class setting.adaptable/flexible, and finding ways to stay productive. Focus group participants commented that communication should be frequent and reliable, but caution against \"over-communication\" that may dilute the intended message or cause email fatigue in which recipients begin ignoring messages due to the sheer volume. They suggest utilizing student leaders to assist in communication with the student body. Further, communication plays a key role in the theme, staying connected. Multiple focus group members commented on the need to maintain connectedness with colleagues, peers, and friends while sheltering at home and social distancing. Methods to stay connected include using virtual platforms to socialize (and not just conduct official school activities) and conducting regular checks of COVID-related stress.Members of each focus group also suggested the crisis created by the COVID-19 pandemic presented a number of opportunities for innovation in the delivery of the curriculum and in maintaining functions, such as college operations and student organization meetings.A key tool for innovation was the distance technology Zoom, with its various functions (e.g., chat, breakout rooms, screenshare) utilized not only for teaching, but also to conduct large and small meetings, interviews, and social events. Related to the theme of turning crisis into opportunity, more than half of all focus group members noted the importance of being flexible and adaptable, as well as finding ways to stay productive during the COVID-19 pandemic. With the swift transition to remote learning, openness and willingness to change teaching methods, communication styles, and study habits were critical to adjustment in the new work and learning environments. Additionally, students and faculty both remarked on the need for structure, whether through a self-made schedule or through synchronous virtual learning (rather than having students view course lecture videos asynchronously), particularly given the potential distractions in the home environment such as having small children nearby when trying to take an exam. For graduate students who were unable to continue lab-based activities, writing assignments (such as manuscript preparation) were provided to facilitate ongoing productivity while working from home. Table 2 presents themes (with supporting quotes) that were unique to each of the focus groups, with at least two members of a given focus group commenting on said issue. The theme \"choose your own reaction\" emerged from comments made by a majority of executive team focus group members. Supporting comments indicated individuals should be deliberate in their response to the challenges presented by the COVID-19 pandemic, such as projecting optimism, being willing to take on new or additional tasks, and focusing on the current situation while continuing to strive toward long-term goals. Among the faculty focus group, the theme of engaging emotions emerged. Faculty members indicated the need to be more intentionally focused on the emotional well-being of students during the pandemic, given the increased level of stress students may be experiencing, both personally and professionally. Likewise, the student focus group acknowledged the need for self-care as well as considering the needs of others whose experiences during the pandemic may be far worse (such as victims of domestic abuse). Turning crisis into opportunity delivery as possible. There were pieces in place to help the process, but we still had to learn a lot since the routine and environment drastically changed. Maintain a culture of optimism that the current crisis will pass; anxiety and fear are wasted energy and emotion.Live one day at a time while keeping long-term goals in mind.Be willing. Be willing to make tough decisions. Be willing to do the small things that add up to big things.Even though I am OK being alone, this has been very hard. By the second week, I was very overwhelmed, and I ended up needing to take a trip home even on a test weekend to be around people.Take time for yourself, being burned out is not helpful for being productive.Be able to see past your own circumstances and be able to think about the deeper needs of the team. Think about other people's difficulties and the effects of abuse and suicide.It is important to talk to students about their feelings and emotions in the situation. In the future, I will be more intentional in talking to students about their emotional response to difficult situations even if it is not related to COVID.We need to help provide emotional stability and positivity. We need to measure the emotional and psychological response of students after the pandemic and see if there is a way for us to improve problems.\n\nDiscussion\n\nThe purpose of this research was to describe leadership lessons learned by academic pharmacy during the COVID-19 pandemic from the perspective of administrators, faculty, and students. Several key themes were identified as similar between the three groups. All groups spoke about the importance of communication, adaptability and flexibility, and maintaining connection. The groups also spoke about the opportunities that can come with crisis and the importance of finding ways to stay productive during periods of tremendous change and uncertainty. There were also some notable responses that were specific to each of the three groups. Administrators focused on the importance of choosing a positive reaction when faced with a challenging situation, such as the COVID-19 pandemic. Students emphasized the importance of self-care, and faculty discussed how this situation taught them to engage the emotions of the students.According to previous research following other types of crises, these leadership lessons are not uncommon in higher education. 13, 20, 21 Although a situation has not affected the country to the extent of COVID-19 in recent history, given the pandemic has continued for more than a year with ongoing social distancing measures, trends in common leadership lessons can be identified from institutions facing individual disasters of various kinds, such as mass shootings, tornados, hurricanes, and other tragedies. The themes of communication and accurate dissemination of information emerged across different types of crises. 13, 20, 21 A specific example of the need for communication is Rice University in the aftermath of Hurricane Harvey. Rice formulated a plan to communicate with each group in a customized way, whether it be undergraduate students, graduate students, or faculty. 20 The same is true for many other campus disasters, such as fires at Butte College and Monmouth University after Hurricane Sandy. 20 Crises can also lead to opportunity and an increased sense of teamwork. 21 Recent research, including the current study, shows themes of opportunity in crisis, connection, and communication, and are thus consistent with studies of lessons learned in prior public emergencies. 22 Although not identified as leadership lessons in the current study, some additional themes detected in prior studies are noteworthy and may be important to academic pharmacy's response to the COVID-19 pandemic and future public health emergencies. For example, previous research found there was a heightened sense of awareness and blurred sense of time during emergent situations, as well as a tremendous amount of guilt that can surround the issue (such as administrators' guilt over not being able to protect their communities). 21 This may suggest a need for increased mental health and well-being support for students, faculty, and staff. In some crisis situations, there is also a need for institutional collaboration and shared resources. While this theme is likely more common for natural disasters like hurricanes, where there is significant destruction of physical property, it may be applicable in the COVID-19 response given the substantial demand placed on digital technology to support remote learning. 20 Reports have emerged of virtual resources that are shared between institutions as a way to collaborate in the current crisis. 20, [23] [24] [25] These resources include websites made by academic institutions, as well as resources for parents, teachers, and staff created by companies like Google and the New York Times.Unsurprisingly, a key theme that emerges from nearly any crisis is the need to pivot or be flexible, as demonstrated in the findings of the current study. 20 One interesting distinction, suggested in an article in The Chronicle of Higher Education, is that natural disasters are discrete and only last for a certain amount of time before recovery starts. However, in the case of COVID-19, the situation is much less predictable. There was limited time to prepare, and there is no definitive end in sight. The ability to rebuild is not as tangible, and the need for flexibility is heightened. 20 An interesting theme that was identified with natural disasters and also emerged in this study was being able to pivot from the focus on students' learning needs to focus on students' emotional needs. As the US has seen through this pandemic, schools are more than just a place for education. They are places of refuge for many and may supply basic needs like food and housing. While these basic physical needs were not identified in the current study, as our students are adults in a professional program, the need to engage students emotionally and take care of the student's mental and emotional health was a theme that emerged. 20, 22 Likewise, the theme of taking care of oneself, identified by our student participants, has also been seen in both disaster situations and the COVID-19 pandemic. 20 As this crisis has caused such a drastic and long-term shift in the way work is done for students, faculty, and administrators across the US, the theme of finding ways to stay productive emerged in this study. In contrast, this was not a common theme in the existing literature concerning previous crisis situations. Key differences include the mass transition to online learning across the country, stay-athome (quarantine) orders, and restrictions in movement and interaction due to the need for social distancing. The home has become office, workplace, library, and classroom for the vast majority of students, faculty, and administrators in higher education. As a result, affected individuals have had to develop new and/or different ways of working and studying in a short period of time. Academic pharmacy must remain attuned to the ever-changing conditions as well as responsive and flexible to the current learning environment in order to facilitate the productivity and success of students and faculty in the face of challenging circumstances.The primary limitation of this study is that qualitative data elicited from purposive samples at one institution may not reflect the thoughts, perceptions, and lessons learned from the broader populations of faculty, administrators, and students in academic pharmacy. Future studies of academic pharmacy leadership during public health emergencies such as COVID-19 should consider utilization of quantitative or mixed-methods designs and larger samples to collect more expansive and generalizable data. However, the themes in this study are consistent with previous research of higher education in emergency situations, supporting the quality and relevance of our qualitative data. Another potential limitation in this study was bias introduced by the focus group moderator or investigators. The moderator for all focus groups asked open-ended questions and did not guide participant responses. Furthermore, investigator bias was mitigated through recording all focus group sessions, transcribing the sessions prior to analysis, and independent review of the transcribed data by three investigators.\n\nConclusions\n\nCore leadership lessons in emergent situations like the COVID-19 pandemic include being adaptable to the changing environment, communicating accurately and with appropriate frequency, finding ways to turn crisis into opportunity, and maintaining connections and productivity to guard against being derailed in achieving goals. As the US continues to face the unknowns of the COVID-19 pandemic, academic pharmacy should also consider the challenges that administrators, faculty, and students have with an indefinite change in routine. The difficulty associated with working from home is new to many of those affected and should be a consideration going forward. COPs should consider developing action plans with tools to help all involved be productive in non-traditional settings. Future research into this topic could include evaluating strategies to help students, faculty, and staff remain productive while at home, as well as the long-term implications of this crisis as campuses consider reopening.\n\nDisclosure(s)\n\nNone.\n\nDeclaration of Competing Interest\n\nMarie Chisholm-Burns serves on the board of directors for the Accreditation Council for Pharmacy Education (ACPE). This manuscript does not represent ACPE or the boards' opinions or views.\n\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro to RAG with LLM"
      ],
      "metadata": {
        "id": "m2cX29CMqUGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing packages\n",
        "!pip install transformers\n",
        "\n",
        "!pip install sentence_transformers\n",
        "!pip install torch\n",
        "!pip install faiss-cpu\n",
        "\n",
        "!pip install -q -U immutabledict sentencepiece"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-18T09:16:08.403401Z",
          "iopub.execute_input": "2025-03-18T09:16:08.403897Z",
          "iopub.status.idle": "2025-03-18T09:16:32.810686Z",
          "shell.execute_reply.started": "2025-03-18T09:16:08.403860Z",
          "shell.execute_reply": "2025-03-18T09:16:32.809241Z"
        },
        "id": "SN0IComxqUGP",
        "outputId": "f44888c9-ebd4-4b1c-b5a9-a18074e09445",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.0.dev0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.50.0.dev0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (0.29.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2025.1.31)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/transformers@v4.49.0-Gemma-3\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-18T09:16:32.812511Z",
          "iopub.execute_input": "2025-03-18T09:16:32.812989Z",
          "iopub.status.idle": "2025-03-18T09:16:56.428675Z",
          "shell.execute_reply.started": "2025-03-18T09:16:32.812947Z",
          "shell.execute_reply": "2025-03-18T09:16:56.427206Z"
        },
        "id": "FGQadvjkqUGP",
        "outputId": "4e6ec658-3eae-41bb-a710-2d5fc5c3510c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers@v4.49.0-Gemma-3\n",
            "  Cloning https://github.com/huggingface/transformers (to revision v4.49.0-Gemma-3) to /tmp/pip-req-build-g3rdroo5\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-g3rdroo5\n",
            "  Running command git checkout -q 1c0f782fe5f983727ff245c4c1b3906f9b99eec2\n",
            "  Resolved https://github.com/huggingface/transformers to commit 1c0f782fe5f983727ff245c4c1b3906f9b99eec2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.0.dev0) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.50.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.50.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.50.0.dev0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.50.0.dev0) (2025.1.31)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.50.0.dev0-py3-none-any.whl size=10936425 sha256=e49301f5f716e7db6567cc31412720bd163bcba6fb8a700a24f31d8f43d0073a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cnxi_9mc/wheels/53/15/d5/d63b866c641d8863f9cd29a4cc7a5efc38476c3aae8247c195\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.48.3\n",
            "    Uninstalling transformers-4.48.3:\n",
            "      Successfully uninstalled transformers-4.48.3\n",
            "Successfully installed transformers-4.50.0.dev0\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import torch\n",
        "from transformers.models.gemma3 import Gemma3ForConditionalGeneration, Gemma3Processor\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-18T09:19:52.369608Z",
          "iopub.execute_input": "2025-03-18T09:19:52.370101Z",
          "iopub.status.idle": "2025-03-18T09:19:52.375544Z",
          "shell.execute_reply.started": "2025-03-18T09:19:52.370066Z",
          "shell.execute_reply": "2025-03-18T09:19:52.374383Z"
        },
        "id": "by5r2GBWqUGP"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "GEMMA_PATH = kagglehub.model_download(\"google/gemma-3/transformers/gemma-3-4b-it\")\n",
        "processor = Gemma3Processor.from_pretrained(GEMMA_PATH, use_fast=True)\n",
        "model = Gemma3ForConditionalGeneration.from_pretrained(GEMMA_PATH, torch_dtype=torch.float16).to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-18T09:20:03.928586Z",
          "iopub.execute_input": "2025-03-18T09:20:03.929033Z",
          "iopub.status.idle": "2025-03-18T09:20:19.673955Z",
          "shell.execute_reply.started": "2025-03-18T09:20:03.928994Z",
          "shell.execute_reply": "2025-03-18T09:20:19.672663Z"
        },
        "id": "xh9GwWwLqUGQ",
        "outputId": "be10e781-b7fb-47f2-adb2-4562ed146fb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KaggleApiHTTPError",
          "evalue": "403 Client Error.\n\nYou don't have permission to access resource at URL: https://www.kaggle.com/models/google/gemma-3/transformers/gemma-3-4b-it/1. The server reported the following issues: Permission denied on resource (or it may not exists).\nPlease make sure you are authenticated if you are trying to access a private resource or a resource requiring consent.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/exceptions.py\u001b[0m in \u001b[0;36mkaggle_api_raise_for_status\u001b[0;34m(response, resource_handle)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://www.kaggle.com/api/v1/models/google/gemma-3/transformers/gemma-3-4b-it/1/files?page_size=25",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKaggleApiHTTPError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-35853f5b65a0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mGEMMA_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkagglehub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"google/gemma-3/transformers/gemma-3-4b-it\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGemma3Processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGEMMA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGemma3ForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGEMMA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/models.py\u001b[0m in \u001b[0;36mmodel_download\u001b[0;34m(handle, path, force_download)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_model_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading Model: {h.to_url()} ...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mEXTRA_CONSOLE_BLOCK\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_resolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/registry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimpl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/resolver.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, handle, path, force_download)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mSome\u001b[0m \u001b[0mcases\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mmight\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCompetition\u001b[0m \u001b[0mdatasource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAPI\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbased\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \"\"\"\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Note handles are immutable, so _resolve() could not have altered our reference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/http_resolver.py\u001b[0m in \u001b[0;36m_resolve\u001b[0;34m(self, h, path, force_download)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;31m# - <= 25 files: Download files in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;31m# > 25 files: Download the archive and uncompress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_more\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_list_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhas_more\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;31m# Downloading the full archived bundle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/http_resolver.py\u001b[0m in \u001b[0;36m_list_files\u001b[0;34m(api_client, h)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_list_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_client\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mKaggleApiV1Client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModelHandle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m     \u001b[0mjson_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_build_list_model_instance_version_files_url_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"files\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjson_response\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Invalid ListModelInstanceVersionFiles API response. Expected to include a 'files' field\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/clients.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, path, resource_handle)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEFAULT_CONNECT_TIMEOUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_READ_TIMEOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         ) as response:\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mkaggle_api_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_for_version_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/exceptions.py\u001b[0m in \u001b[0;36mkaggle_api_raise_for_status\u001b[0;34m(response, resource_handle)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# Default handling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKaggleApiHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKaggleApiHTTPError\u001b[0m: 403 Client Error.\n\nYou don't have permission to access resource at URL: https://www.kaggle.com/models/google/gemma-3/transformers/gemma-3-4b-it/1. The server reported the following issues: Permission denied on resource (or it may not exists).\nPlease make sure you are authenticated if you are trying to access a private resource or a resource requiring consent."
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"<start_of_turn>user\n",
        "Write a poem about the Kraken<end_of_turn>\n",
        "<start_of_turn>model\"\"\"\n",
        "input_ids = processor(text=prompt, return_tensors=\"pt\").to(device)\n",
        "outputs = model.generate(**input_ids, max_new_tokens=512)\n",
        "text = processor.batch_decode(\n",
        "    outputs,\n",
        "    skip_special_tokens=True,\n",
        "    clean_up_tokenization_spaces=False\n",
        ")\n",
        "print(text[0])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-18T09:27:08.431422Z",
          "iopub.execute_input": "2025-03-18T09:27:08.432077Z"
        },
        "id": "qo1Yq_mJqUGQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "\n",
        "# Importing system\n",
        "import faiss\n",
        "\n",
        "# Importing Libraries LLM\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForCausalLM\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-18T08:47:20.158352Z",
          "iopub.execute_input": "2025-03-18T08:47:20.158828Z",
          "iopub.status.idle": "2025-03-18T08:47:20.192681Z",
          "shell.execute_reply.started": "2025-03-18T08:47:20.158794Z",
          "shell.execute_reply": "2025-03-18T08:47:20.191194Z"
        },
        "id": "QmVtnomgqUGQ",
        "outputId": "6f8742b6-3f7d-4ca4-b918-a7acf8e47edd"
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-bae96c9b9457>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#from transformers.models.gemma3 import Gemma3ForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgemma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGemma3ForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Gemma3ForCausalLM' from 'gemma.model' (/kaggle/working/gemma_pytorch/gemma/model.py)"
          ],
          "ename": "ImportError",
          "evalue": "cannot import name 'Gemma3ForCausalLM' from 'gemma.model' (/kaggle/working/gemma_pytorch/gemma/model.py)",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-03-18T09:01:37.537Z"
        },
        "id": "6fFHuQyRqUGQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One more take, with huggin face gemma"
      ],
      "metadata": {
        "id": "7xyKL-W5sIbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "# Note: `userdata.get` is a Colab API. If you're not using Colab, set the env\n",
        "# vars as appropriate for your system.\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")"
      ],
      "metadata": {
        "id": "HQJOigCXsP_j"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install --upgrade -q transformers huggingface_hub peft \\\n",
        "  accelerate bitsandbytes datasets trl"
      ],
      "metadata": {
        "id": "4oisrWyftVpQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login(os.environ[\"HF_TOKEN\"])"
      ],
      "metadata": {
        "id": "Kaqt5vTNtYQJ",
        "outputId": "467b7062-5ed8-4086-9478-85518bfe8520",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "model_id = \"google/gemma-3-4b-it\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        ""
      ],
      "metadata": {
        "id": "CTgdSueCtfOx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's load the tokenizer first\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "eQHqtFh_t0qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_id, use_fast=True)\n",
        "model = AutoModelForImageTextToText.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "QSnQpsj-xe8v",
        "outputId": "dd4d795e-d9fc-4b80-ca94-3411e9b02dfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5db5c863adda488aaf948503c41b4e70",
            "c99d959ee82d4a51ac1cdb7553067324",
            "ad886c9c1111444c9101d8d5903b056e",
            "713f885c5a23448db57ed389256b5038",
            "f211a749f62142b8b03e10d9e4dca3b7",
            "71355d7648224254866924478734cad0",
            "95f5c48793074293b27f9f9c1b625d1b",
            "aaa4a1f27dd748899ae6fd4c57ad3956",
            "f5edc674fd4347db9d39cfd50a58cdb9",
            "71b5c2e9d6a041ef8ee8082885fa550d",
            "3ae07928e2644ac9b8afe3ff2f34dd4f"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5db5c863adda488aaf948503c41b4e70"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fresh approach with hugging face\n",
        "\n",
        "Following [https://huggingface.co/docs/transformers/en/tasks/question_answering](http://)"
      ],
      "metadata": {
        "id": "QeRbEEFuqUGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch pytesseract\n",
        "!pip install sentencepiece sacremoses"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-18T08:36:25.416322Z",
          "iopub.execute_input": "2025-03-18T08:36:25.416659Z",
          "iopub.status.idle": "2025-03-18T08:38:23.273560Z",
          "shell.execute_reply.started": "2025-03-18T08:36:25.416633Z",
          "shell.execute_reply": "2025-03-18T08:38:23.272270Z"
        },
        "id": "UUvyhz3SqUGQ",
        "outputId": "8e4253dc-60d6-4e9d-87c4-00191e6f6a5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (11.0.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7afcc7565240>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/sacremoses/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7afcc7565570>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/sacremoses/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7afcc7565720>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/sacremoses/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7afcc75658d0>: Failed to establish a new connection: [Errno -2] Name or service not known')': /simple/sacremoses/\u001b[0m\u001b[33m\n\u001b[0mCollecting sacremoses\n  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2024.11.6)\nRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.4.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.67.1)\nDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sacremoses\nSuccessfully installed sacremoses-0.1.1\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#from huggingface_hub import notebook_login\n",
        "#notebook_login()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-17T16:48:21.916692Z",
          "iopub.execute_input": "2025-03-17T16:48:21.917069Z",
          "iopub.status.idle": "2025-03-17T16:48:21.939497Z",
          "shell.execute_reply.started": "2025-03-17T16:48:21.917041Z",
          "shell.execute_reply": "2025-03-17T16:48:21.938395Z"
        },
        "id": "ISuJPcmZqUGQ",
        "outputId": "e2a45af2-2f11-4b50-8006-4116ff2a59eb",
        "colab": {
          "referenced_widgets": [
            "4d85578fb3ba4bde8b98667b4b374da1"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d85578fb3ba4bde8b98667b4b374da1"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-18T08:39:33.243330Z",
          "iopub.execute_input": "2025-03-18T08:39:33.243710Z",
          "iopub.status.idle": "2025-03-18T08:39:59.539619Z",
          "shell.execute_reply.started": "2025-03-18T08:39:33.243677Z",
          "shell.execute_reply": "2025-03-18T08:39:59.538415Z"
        },
        "id": "PDvcsmovqUGR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "tD8_mL9yqUGR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "SNWCkjJjqUGR"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}