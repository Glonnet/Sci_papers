{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b3bb6fa-287c-4b9c-b6b1-10579c009a8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0a6f049-c419-4d32-84e7-607a6552ac3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket_name = \"sci_papers_bootcamp\"\n",
    "project_name=\"jakub-le-wagon-bootcamp\"\n",
    "prefix = 'cord19/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88fca27d-d834-43bc-80a7-a4ce93adab6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize GCS client\n",
    "storage_client = storage.Client(project=project_name)\n",
    "bucket = storage_client.bucket(bucket_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d92e97e-6b52-4a37-ac01-b98672d6a3f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing existing files in the bucket...\n",
      "Found 92783 files already in the bucket\n"
     ]
    }
   ],
   "source": [
    "# Get list of files already in the bucket\n",
    "print(\"Listing existing files in the bucket...\")\n",
    "existing_files = set()\n",
    "\n",
    "blobs = bucket.list_blobs(prefix=prefix)\n",
    "for blob in blobs:\n",
    "    # Remove the prefix to get just the relative path\n",
    "    if blob.name.startswith(prefix):\n",
    "        existing_files.add(blob.name[len(prefix):])\n",
    "\n",
    "print(f\"Found {len(existing_files)} files already in the bucket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304b6c57-d153-4ca1-b5c6-9cc223ac0713",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Processing of input json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a2ba4f1-9950-44bb-89cf-48218a1c16f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "640749c2-1bfa-4626-91b5-cb3e8a955392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_article(file):\n",
    "    paper_id = file['paper_id']\n",
    "    body = \"\"\n",
    "    \n",
    "    body += file['metadata']['title']\n",
    "    body += \"\\n\\n\"\n",
    "    if len(file['abstract']) > 0:\n",
    "        body += file['abstract'][0]['section']\n",
    "        body += \"\\n\\n\"\n",
    "        body += file['abstract'][0]['text']\n",
    "        body += \"\\n\\n\"\n",
    "    \n",
    "    texts = [(di['section'], di['text']) for di in file['body_text']]\n",
    "    texts_di = {di['section']: \"\" for di in file['body_text']}\n",
    "    for section, text in texts:\n",
    "        texts_di[section] += text\n",
    "    \n",
    "    for section, text in texts_di.items():\n",
    "        body += section\n",
    "        body += \"\\n\\n\"\n",
    "        body += text\n",
    "        body += \"\\n\\n\"\n",
    "    \n",
    "    \n",
    "    return {\"paper_id\": paper_id, \"content\" : body}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "148ce63b-c861-4f88-82ab-1aed7b7bd528",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_batch(batch_blobs, bucket_name):\n",
    "    processed_data = []\n",
    "    \n",
    "    for blob in tqdm(batch_blobs, desc=\"Processing files\"):\n",
    "        # Read content directly into memory\n",
    "        content = blob.download_as_text()\n",
    "        \n",
    "        # Parse JSON\n",
    "        try:\n",
    "            data = json.loads(content)\n",
    "            processed_data.append(process_article(data))\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing {blob.name}: {e}\")\n",
    "    \n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1033b10-29a9-4019-800a-d38b281e87a1",
   "metadata": {},
   "source": [
    "# Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "89333abc-78eb-4f3c-8eb6-9f5a617cc208",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (25.0)\n",
      "Collecting pip\n",
      "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 25.0\n",
      "    Uninstalling pip-25.0:\n",
      "      Successfully uninstalled pip-25.0\n",
      "Successfully installed pip-25.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-text-splitters in /opt/conda/lib/python3.10/site-packages (0.3.7)\n",
      "Requirement already satisfied: langchain-community in /opt/conda/lib/python3.10/site-packages (0.3.20)\n",
      "Requirement already satisfied: langgraph in /opt/conda/lib/python3.10/site-packages (0.3.16)\n",
      "Requirement already satisfied: langchain_huggingface in /opt/conda/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /opt/conda/lib/python3.10/site-packages (from langchain-text-splitters) (0.3.45)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.21 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.3.21)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (3.11.12)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.8.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.3.17)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /opt/conda/lib/python3.10/site-packages (from langgraph) (2.0.21)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from langgraph) (0.1.3)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /opt/conda/lib/python3.10/site-packages (from langgraph) (0.1.57)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langchain_huggingface) (0.29.3)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from langchain_huggingface) (3.4.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from langchain_huggingface) (0.21.1)\n",
      "Requirement already satisfied: transformers>=4.39.0 in /opt/conda/lib/python3.10/site-packages (from langchain_huggingface) (4.49.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2025.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (24.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.10/site-packages (from langchain<1.0.0,>=0.3.21->langchain-community) (2.10.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (1.33)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /opt/conda/lib/python3.10/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /opt/conda/lib/python3.10/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.15.1)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (11.1.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.0->langchain_huggingface) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.0->langchain_huggingface) (0.5.3)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (2.27.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-gpu in /opt/conda/lib/python3.10/site-packages (1.7.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade langchain-text-splitters langchain-community langgraph langchain_huggingface\n",
    "!pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0aab702e-7d0b-441a-9e7d-bb16af4de0e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f80b5796149415daa80d2c6bf6779b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e284ae0ba0e4ced8e7de86fc2ed4d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04161471a8ee4c35add962eeef76d4fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e077f3db662457296a976a04fb12811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c826f91d5e5a4267a48548e34ceb088c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11420cd66a9a469c960938731af64814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20698f7ddef84324b6ef80232613961a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdae0f561c194af1a8c22643f898f1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d7a4e1b311846e4a16ffba0c086044d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da8678258244765a2d66a700e7dd65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0a017b5a0b4126be0e364cd3a231c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "#embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "25d4cf6c-b76d-4c10-baf7-25e32fa9a902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "index = faiss.IndexFlatL2(len(embeddings.embed_query(\"hello world\")))\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    "#    persist_directory = \"faiss\", #https://docs.langflow.org/components-vector-stores#inputs-8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "52f64029-2a97-4baa-ac17-00fcc43197de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0de911f4-2287-4ff7-b48f-6aa8c9ff6d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vectorize_batch(batch, vectore_store, splitter):\n",
    "    \"\"\"\n",
    "    Process a batch of articles, split them into chunks, and add to FAISS vector store.\n",
    "    \n",
    "    Args:\n",
    "        batch: List of dictionaries, each with 'paper_id' and 'content' keys\n",
    "    \"\"\"\n",
    "    \n",
    "    texts = []\n",
    "    metadatas = []\n",
    "    \n",
    "    # Process each article in the batch\n",
    "    for paper in tqdm(batch, desc=\"Vectorizing files\"):\n",
    "        paper_id = paper['paper_id']\n",
    "        content = paper['content']\n",
    "        \n",
    "        # Skip if missing required fields\n",
    "        if not paper_id or not content:\n",
    "            continue\n",
    "        \n",
    "        # Split the article into chunks\n",
    "        chunks = splitter.split_text(content)\n",
    "        \n",
    "        # Add each chunk with its metadata\n",
    "        for i, chunk_text in enumerate(chunks):\n",
    "            texts.append(chunk_text)\n",
    "            metadatas.append({\n",
    "                'paper_id': paper_id,\n",
    "                'chunk_id': f\"{paper_id}_chunk_{i}\",\n",
    "                'source': paper_id\n",
    "            })\n",
    "    \n",
    "    # Skip if no chunks were created\n",
    "    if not texts:\n",
    "        return\n",
    "    \n",
    "    # Add to FAISS vector store\n",
    "    print(f\"Adding {len(texts)} chunks into vector DB\")\n",
    "    vector_store.add_texts(texts, metadatas)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46b0c9d-060d-4e30-a4e7-953af7b05b00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874642d7-b99e-4eaa-9433-c25051c1a516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e68d59-49c8-4e0b-879f-c90eb80f3171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf058a49-e16f-47b7-a501-b7041fee8ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb531cf5-56bf-4abb-8d9c-b7986ffcfade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cdd57f-76c3-4c2f-9512-c2e4da8b16d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467db305-a8ab-472f-a55a-f6afda2d0832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dc178e-da94-4cf4-88e7-b41ca4587a03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a61d88-8bc0-4107-b915-0571dffaaf07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1845164-680d-4d4e-a93d-230c0f582ca9",
   "metadata": {},
   "source": [
    "# Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a108658d-0205-4d8b-83a6-de889b192ab1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 files in the bucket\n",
      "Processing batch 1/200 (500 files)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  76%|███████▋  | 382/500 [00:13<00:05, 23.18it/s]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# List all blobs in the bucket with the given prefix\n",
    "all_blobs = list(bucket.list_blobs(prefix=prefix, max_results=100000))\n",
    "total_files = len(all_blobs)\n",
    "print(f\"Found {total_files} files in the bucket\")\n",
    "\n",
    "batch_size = 500\n",
    "\n",
    "# Process in batches\n",
    "for i in range(0, total_files, batch_size):\n",
    "    batch_end = min(i + batch_size, total_files)\n",
    "    current_batch = all_blobs[i:batch_end]\n",
    "\n",
    "    print(f\"Processing batch {i//batch_size + 1}/{(total_files-1)//batch_size + 1} ({len(current_batch)} files)\")\n",
    "\n",
    "    # Process the current batch\n",
    "    processed_batch = process_batch(current_batch, bucket_name)\n",
    "    vectorize_batch(processed_batch, vector_store, splitter) \n",
    "\n",
    "    print(f\"Successfully processed {len(processed_batch)} files in the current batch\")\n",
    "\n",
    "    # Clear memory\n",
    "    del processed_batch\n",
    "\n",
    "vector_store.save_local(\"faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ddf32f-8ef4-44a6-82bd-cd237ea0847a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714254e0-f98d-468a-b8e3-7d56087ccebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd72fc64-3f6a-425f-9118-93eb49c20320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f411c786-52b6-448f-bb1a-e7aff3da3c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19350bd7-e821-4df3-b0c3-efc85c1b2028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0d0fd05d-2a30-4efa-9dc3-e853901f7ec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pwd\n",
    "#/home/jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f3f6f2d8-6800-4d9c-a2ac-61ce9b14a3f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.mkdir(\"faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3be418a0-a844-4aca-8699-0d02e850e1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vew_vs = FAISS.load_local(\"faiss\", embeddings=embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c61594f3-91cc-437f-9a74-fe6665ef0752",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"What is the efficacy of various vaccines?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e3a2e5e8-5649-4160-bb55-23e72b7e3dd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='7e58775b-4c3c-4eb8-9f8f-950d6b7f8f23', metadata={'article_id': '00046b27022615aaec3782ea69c56da3d2fd2ffa', 'chunk_id': '00046b27022615aaec3782ea69c56da3d2fd2ffa_chunk_10', 'source': '00046b27022615aaec3782ea69c56da3d2fd2ffa'}, page_content='weakened immune systems. These factors also cause different diseases like obesity, metabolic syndrome, type II diabetes, and immunemediated cancers. The reasons for developing these diseases include reduction of immune cell levels and their function, a weak affinity for antigen recognition, the increased time required for humoral immune responses, and defect of memory cells [42] . Moreover, the administration of immunosuppressive medicines [46] and habitation in lowincome countries with a low socioeconomic position lead to more mortality compared with high-income countries [47] . Other important factors that impact the ineffectiveness of the COVID-19 vaccine are the high rate of obesity because of increased secretion of IL-6 and decreased levels of IgG, pneumonia, and parasitic infections [42] .Globally, different types of vaccines are developing against COVID-19 which introduce antigens to the immune system in various manners. These include weakened or inactivated vaccines, viral vector vaccines, protein-based vaccines, and RNA and DNA vaccines [43] . It is demonstrated that weakened or inactivated vaccines have functioned well because of having two required signals to stimulate the immune system: the antigen and the natural adjuvant. The antigen induces a specific adaptive immune response for the special pathogen, and the adjuvants induce the innate immune response via pattern recognition receptors (PRRs) recognizing pathogen-associated molecular patterns (PAMPS) [48] . An antigen could be immunogenic if it contained PAMPS inducing PRRs like Toll-like receptors (TLRs) and viral nucleic acid sensors (RIG-I and cGAS) in antigen-presenting cells. Since dendritic cells are the major type of cells for inducing an adaptive immune response, involvement of different expressed PRRs on a particular subset of dendritic cells leads to activation and migration of these cells to lymph nodes where the lymphocytes of the adaptive immune response are recruited to fight with a'),\n",
       " Document(id='6a210ea8-5668-481d-a60f-c7be44806c6e', metadata={'article_id': '00046b27022615aaec3782ea69c56da3d2fd2ffa', 'chunk_id': '00046b27022615aaec3782ea69c56da3d2fd2ffa_chunk_10', 'source': '00046b27022615aaec3782ea69c56da3d2fd2ffa'}, page_content='weakened immune systems. These factors also cause different diseases like obesity, metabolic syndrome, type II diabetes, and immunemediated cancers. The reasons for developing these diseases include reduction of immune cell levels and their function, a weak affinity for antigen recognition, the increased time required for humoral immune responses, and defect of memory cells [42] . Moreover, the administration of immunosuppressive medicines [46] and habitation in lowincome countries with a low socioeconomic position lead to more mortality compared with high-income countries [47] . Other important factors that impact the ineffectiveness of the COVID-19 vaccine are the high rate of obesity because of increased secretion of IL-6 and decreased levels of IgG, pneumonia, and parasitic infections [42] .Globally, different types of vaccines are developing against COVID-19 which introduce antigens to the immune system in various manners. These include weakened or inactivated vaccines, viral vector vaccines, protein-based vaccines, and RNA and DNA vaccines [43] . It is demonstrated that weakened or inactivated vaccines have functioned well because of having two required signals to stimulate the immune system: the antigen and the natural adjuvant. The antigen induces a specific adaptive immune response for the special pathogen, and the adjuvants induce the innate immune response via pattern recognition receptors (PRRs) recognizing pathogen-associated molecular patterns (PAMPS) [48] . An antigen could be immunogenic if it contained PAMPS inducing PRRs like Toll-like receptors (TLRs) and viral nucleic acid sensors (RIG-I and cGAS) in antigen-presenting cells. Since dendritic cells are the major type of cells for inducing an adaptive immune response, involvement of different expressed PRRs on a particular subset of dendritic cells leads to activation and migration of these cells to lymph nodes where the lymphocytes of the adaptive immune response are recruited to fight with a'),\n",
       " Document(id='942f8dec-b732-478a-a394-9e73cef552b2', metadata={'article_id': '0012a43f0802101e49ddbbbd115aac4f48044746', 'chunk_id': '0012a43f0802101e49ddbbbd115aac4f48044746_chunk_9', 'source': '0012a43f0802101e49ddbbbd115aac4f48044746'}, page_content=\"From the first variolated smallpox vaccine by English physician Edward Jenner in 1796 to the era of gene-based vaccines, there are now over 70 approved vaccines available. s96 Their effectiveness has been recently comprehensively reviewed by Nabel, who calculated that tens of millions of people died from nowpreventable infections before vaccination was introduced in the 20th century (>17 million deaths from diphtheria alone). s96 Vaccines can be classified into live/attenuated, non-live/inactivated and gene-based. The principle of live vaccines is based on the attenuation of the virus or its ability to replicate through genetic modification. This can be achieved, for example, by optimal growth at a lower temperature (cold-adapted). s97,s98 Live vaccines generate a strong immunity; however, they are associated with risk of symptomatic disease, especially in immunocompromised individuals. s99 Inactivated vaccines (subsuming inactivation, subunit, split vaccine, conjugate vaccine) have the advantage of not causing infection since only an inactivated pathogen or components thereof are administered, but at the sacrifice of lower immunogenicity and shorter immunity. s100 Adjuvants, components that trigger an enhanced antigenspecific immune response, are therefore often used to stimulate the immune response and encompass aluminium salts, lipid A analogues or emulsions. s101 The third category are gene-based vaccines, including vector vaccines and mRNA vaccines. s102,s103 Vector vaccines are typically based on an engineered 'vector' virus that has been genetically modified to express, for example, the SARS-CoV-2 spike protein, and is prevented from replicating in vivo. s104 In the case of the 'Gam-COVID-Vac', also known as the Sputnik V vaccine, two recombinant non-replicating human adenoviruses were used (two for minimising immune response against vector components), and in the case of the 'ChAdOx1 nCoV-19' an unreplicable chimpanzee adenovirus is used. s105,s106On the\"),\n",
       " Document(id='a382b074-24f3-4dd2-8d32-1a88320e49ab', metadata={'article_id': '00046b27022615aaec3782ea69c56da3d2fd2ffa', 'chunk_id': '00046b27022615aaec3782ea69c56da3d2fd2ffa_chunk_32', 'source': '00046b27022615aaec3782ea69c56da3d2fd2ffa'}, page_content='The vaccination route is so important as it will determine the strength of viral antigens immunogenically and the vaccine\\'s protective immunity and durability [104] . For the respiratory mucosal pathogens like \"SARS-CoV-2\", the vaccination route needs to adapt innate immunity and neutralizing antibodies [105] . The COVID-19 vaccine is passed through the muscles like current vaccines (parenteral or injectable route of vaccination) used for human immunization [106] . The optimal time for this route is the COVID-19 asymptomatic period which is 2 to 12 days since most of the immune protective factors are in the respiratory mucosa before injection [107, 108] . The injectable route of vaccination induces IgG antibodies as the principal vaccine mechanism to protect humans. This route of vaccination is not much effective on T cells and IgA antibodies in the lungs [109] .A respiratory mucosal vaccine strategy is another route that induces the respiratory mucosa directly, and it is very effective in control and clearance of this harmful virus. It induces T cells and antibodies, especially IgG, in respiratory mucosa and macrophages [104] . The recombinant viral vaccines, especially with Ad5, are effective and safe for the respiratory mucosal vaccine [110] . Using nasal delivery in the nanovaccine approach, which mimics the virosome, can prevent virus infection in the respiratory tract. Being needle-free and needing smaller doses than the injectable route are some of the advantages of this strategy. Still, it requires safer platforms for respiratory vaccination and inhalational equipment, limiting factors in public applications [108] .Another developed vaccination technique is the vaccines based on DNA and mRNA used to encode the antigen proteins in the cells, as spike protein in COVID-19. This kind of vaccine induces the DNA or RNA into the cells to produce protein in the cell surface to immunize the body [105] . The biggest challenge of these vaccines is that the target'),\n",
       " Document(id='b27e6da4-0b83-441e-a7ef-af3fe7f9f246', metadata={'article_id': '00046b27022615aaec3782ea69c56da3d2fd2ffa', 'chunk_id': '00046b27022615aaec3782ea69c56da3d2fd2ffa_chunk_32', 'source': '00046b27022615aaec3782ea69c56da3d2fd2ffa'}, page_content='The vaccination route is so important as it will determine the strength of viral antigens immunogenically and the vaccine\\'s protective immunity and durability [104] . For the respiratory mucosal pathogens like \"SARS-CoV-2\", the vaccination route needs to adapt innate immunity and neutralizing antibodies [105] . The COVID-19 vaccine is passed through the muscles like current vaccines (parenteral or injectable route of vaccination) used for human immunization [106] . The optimal time for this route is the COVID-19 asymptomatic period which is 2 to 12 days since most of the immune protective factors are in the respiratory mucosa before injection [107, 108] . The injectable route of vaccination induces IgG antibodies as the principal vaccine mechanism to protect humans. This route of vaccination is not much effective on T cells and IgA antibodies in the lungs [109] .A respiratory mucosal vaccine strategy is another route that induces the respiratory mucosa directly, and it is very effective in control and clearance of this harmful virus. It induces T cells and antibodies, especially IgG, in respiratory mucosa and macrophages [104] . The recombinant viral vaccines, especially with Ad5, are effective and safe for the respiratory mucosal vaccine [110] . Using nasal delivery in the nanovaccine approach, which mimics the virosome, can prevent virus infection in the respiratory tract. Being needle-free and needing smaller doses than the injectable route are some of the advantages of this strategy. Still, it requires safer platforms for respiratory vaccination and inhalational equipment, limiting factors in public applications [108] .Another developed vaccination technique is the vaccines based on DNA and mRNA used to encode the antigen proteins in the cells, as spike protein in COVID-19. This kind of vaccine induces the DNA or RNA into the cells to produce protein in the cell surface to immunize the body [105] . The biggest challenge of these vaccines is that the target')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vew_vs.search(query, search_type=\"similarity\", k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b34f0d7-9446-4a56-8734-e80b3f2ca8bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
